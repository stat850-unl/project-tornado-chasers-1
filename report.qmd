---
format: html
editor: visual
---

```{r, eval = F}
# This code chunk contains code to install all of the dependencies
# necessary to compile and run your report, using if-statements to
# reduce install time for unnecessary code.
# It should be set to eval = F by default, so you aren't installing
# software on someone's computer without their consent.

# This works for packages that are on CRAN
if (!"dplyr" %in% installed.packages()) {
  install.packages("dplyr")
}
if (!"remotes" %in% installed.packages()) {
  install.packages("remotes")
}

# This is how to do it for a package that's only on github
if (!"emo" %in% installed.packages()) {
  remotes::install_github("hadley/emo")

```

```{r}

```

## Introduction

A tornado is a rapidly rotating column of air that extends from a thunderstorm to the ground, forming a funnel-shaped cloud, known as a tornado vortex ([Tornadoes.(n.d.)](https://www.nssl.noaa.gov/research/tornadoes/)). These violent windstorms are characterized by their destructive power, often causing severe damage to structures, vehicles, and natural environments. So this most destructive and fascinating natural phenomena that occur in the United States, with the power to wreak havoc on communities, devastate landscapes, and claim lives. They are often referred to as nature's most violent storms due to their ferocity and unpredictability. In the USA, tornadoes have long been a subject of both fear and awe, prompting researchers, meteorologists, and emergency response teams to seek a deeper understanding of these formidable weather events.

The interest in exploring this extensive tornado data set arises from the profound impact that tornadoes have on American society and the natural environment. Tornadoes are a recurring and unpredictable threat, causing significant economic losses and, more importantly, putting human lives at risk. As a researcher, I am driven by the need to better understand the behavior and patterns of tornadoes to mitigate their destructive potential and improve our ability to predict and respond to them.

The opportunity to delve into a comprehensive data set, spanning more than seven decades, is both exciting and promising. It allows for a deep exploration of trends, anomalies, and potential patterns in tornado occurrence and behavior, which can inform disaster preparedness, risk assessment, and policy development.

## Data

### Source

The data source for the project is comes from - [TidyTuesday Archive](https://github.com/rfordatascience/tidytuesday) data project, and the data set used is the [Tornado Data](https://www.spc.noaa.gov/wcm/data/1950-2022_actual_tornadoes.csv).

```{r, echo = F,message = F, warning = F}

library(tidyverse)

#read the data

tornado <-read.csv("https://www.spc.noaa.gov/wcm/data/1950-2022_actual_tornadoes.csv")

#print the data information
str(tornado)

```

### Description

This data set provides comprehensive information about tornadoes, including various attributes such as tornado numbers, years, months, days, dates, times, geographical coordinates, magnitudes, injuries, fatalities, property losses, and more. The data offers insights into the characteristics and impacts of tornadoes that have occurred from 1950 to 2022.

It is sourced from NOAA's National Weather Service Storm Prediction Center Severe Weather Maps, Graphics, and Data Page ([Storm Prediction](https://www.spc.noaa.gov/wcm/)).This offers a rich resource for the analysis and study of tornado occurrences and their impacts, enabling researchers and meteorologists to gain insights into the patterns and characteristics of tornadoes spanning over seven decades.

## Project Goals

The [Tornado Data](https://www.spc.noaa.gov/wcm/data/1950-2022_actual_tornadoes.csv) set from NOAA, covering the years 1950 to 2022, is fascinating because it holds the potential to reveal valuable insights.

The goals of this project are to utilize this data to explore and analyze several key aspects related to tornado occurrences in the United States. Here are the specific goals and the intriguing subjects we hope to investigate.

## Methods

libraries

```{r}
library(tidyverse)
library(stringr)
library(tmap)
library(ggplot2)
library(usmap)
library(showtext)

```

### Data Cleaning and Pre-processing

**1. Conduct data cleaning to handle missing values, outliers, and inconsistencies in the tornado data set, ensuring that the data is of high quality for analysis.**

-   Print the data information

```{r, echo = F,message = F, warning = F}
#print the data information
str(tornado)

```

The data.frame "tornado" has 29 variables and 68,701 observations.

-   Check for missing values in the data set.

```{r}
# Check for missing values in each column
missing_values <- colSums(is.na(tornado))

# Print the results
print(missing_values)

```

It looks like the output indicates that there are no missing values in any of the columns of your "tornado" data frame. Each column has a count of 0, meaning there are no missing values.

-   Identify and Handling Inconsistent Values

```{r}
summary(tornado)
```

some potential issues or considerations based on the summary:

I. "mag" (Magnitude) Column:

The minimum value is -9, which may be inconsistent since magnitude is typically a non-negative value.

Identify rows which have negative magnitude.

```{r}
# Identify rows where magnitude is negative

negative_mag_rows <- tornado[tornado$mag < 0, ] 
mag_neg<-(negative_mag_rows[, c("om", "yr", "mo", "dy", "mag","fc")])


num_rows <- nrow(mag_neg)

print(paste('No of rows where magnitude is negative:', num_rows))


```

Identify years where magnitude is negative.

```{r}
# Identify years where magnitude is negative

print(unique(negative_mag_rows$yr))

```

These rows seem to represent tornadoes from year 2016-2022 where the original magnitude ("mag") is listed as -9, and the "fc" value is set to 0, according to the modification scheme (ref) indicating that no modification was made for these tornadoes.

This output aligns where tornadoes with a F-scale rating of -9 were not modified based on property loss and path length criteria.

(https://www.spc.noaa.gov/wcm/#data https://www.spc.noaa.gov/wcm/OneTor_F-scale-modifications.pdf)

II. "date" and "time" Columns:

Confirm that the "date" and "time" columns are correctly formatted as dates and times, respectively.

```{r}
# Convert "date" to Date class
tornado$date <- as.Date(tornado$date, format="%Y-%m-%d")

# Convert "time" to POSIXct class
tornado$time <- as.POSIXct(tornado$time, format="%H:%M:%S")

```

III. "st" Column:

Create a separate column called "state_full" which have the full state name.

```{r}

# Create a mapping between state abbreviations and full names
state_mapping <- c("AL" = "Alabama", "AK" = "Alaska", "AZ" = "Arizona", "AR" = "Arkansas", "CA" = "California",
                   "CO" = "Colorado", "CT" = "Connecticut", "DE" = "Delaware", "FL" = "Florida", "GA" = "Georgia",
                   "HI" = "Hawaii", "ID" = "Idaho", "IL" = "Illinois", "IN" = "Indiana", "IA" = "Iowa",
                   "KS" = "Kansas", "KY" = "Kentucky", "LA" = "Louisiana", "ME" = "Maine", "MD" = "Maryland",
                   "MA" = "Massachusetts", "MI" = "Michigan", "MN" = "Minnesota", "MS" = "Mississippi", "MO" = "Missouri",
                   "MT" = "Montana", "NE" = "Nebraska", "NV" = "Nevada", "NH" = "New Hampshire", "NJ" = "New Jersey",
                   "NM" = "New Mexico", "NY" = "New York", "NC" = "North Carolina", "ND" = "North Dakota", "OH" = "Ohio",
                   "OK" = "Oklahoma", "OR" = "Oregon", "PA" = "Pennsylvania", "RI" = "Rhode Island", "SC" = "South Carolina",
                   "SD" = "South Dakota", "TN" = "Tennessee", "TX" = "Texas", "UT" = "Utah", "VT" = "Vermont",
                   "VA" = "Virginia", "WA" = "Washington", "WV" = "West Virginia", "WI" = "Wisconsin", "WY" = "Wyoming")

# Add a new column with full state names
tornado$state_full <- state_mapping[tornado$st]

# Print the first few rows to verify
head(tornado[, c("st", "state_full")])
```

### Tornado Trends and Patterns

**1. Examine long-term trends in tornado frequency and intensity, and identify any significant changes over the decades. Are tornadoes becoming more frequent or intense over time.**

Steps to examine long-term trends in tornado frequency and intensity and identify any significant changes over the decades.

I. Subset the Data for Relevant Variables:

Focus on the variables that are crucial for examining tornado frequency and intensity trends. These may include the year (`yr`), month (`mo`), magnitude (`mag`), and other relevant variables.

```{r}
# Subset the data
tornado_subset <- tornado[, c("yr", "mo", "mag")]
```

II. Aggregate Tornado Frequency by Year:

Calculate the total number of tornadoes per year to examine the frequency trend.

```{r}
# Aggregate tornado frequency by year
tornado_frequency <- aggregate(mag ~ yr, data = tornado_subset, FUN = length)
```

III. Plot Tornado Frequency Over Time:

Create a plot to visualize the trend in tornado frequency over the years.

```{r}
# Fit linear trend line for tornado frequency
trend_frequency <- lm(mag ~ yr, data = tornado_frequency)

# Plot tornado frequency over time with trend lines
plot(tornado_frequency$yr, tornado_frequency$mag, type = "l", xlab = "Year", ylab = "Tornado Frequency", main = "Tornado Frequency Over Time with Trend Line")
abline(trend_frequency, col = "red")
```

IV. Explore Tornado Intensity Trends:

Examine trends in tornado intensity (magnitude) over time. And calculate the average magnitude per year.

```{r}
# Aggregate average tornado magnitude by year
tornado_intensity <- aggregate(mag ~ yr, data = tornado_subset, FUN = mean)

```

IV. Plot Tornado Intensity Over Time:\*\*

Visualize the trend in tornado intensity over the years.

```{r}
# Fit linear trend line for tornado intensity
trend_intensity <- lm(mag ~ yr, data = tornado_intensity)

# Plot tornado intensity over time
plot(tornado_intensity$yr, tornado_intensity$mag, type = "l", xlab = "Year", ylab = "Average Tornado Magnitude", main = "Tornado Intensity Over Time with Trend Line")
abline(trend_intensity, col = "red")

```



VI. Interpret the Results:

**The tornado frequency over the years:**

The increasing trend in tornado frequency from 1950 to 2022, is a positive slope of the trend line in the plot, suggests a general rise in the number of reported tornadoes over the years.

The pattern (zig-zag)indicate some variability in tornado frequency from year to year. This could be influenced by various factors, such as natural climate variability, advancements in technology and reporting, or other external factors.

**The tornado intensity over the years:**








**2. Investigate seasonal and regional variations in tornado occurrences. Are there particular months or states with higher tornado activity.**

Steps to investigate seasonal and regional variations in tornado occurrences using interactive maps.

I. Prepare Data for Mapping:

Subset the data to include relevant variables for mapping, such as latitude (`slat` and `elat`), longitude (`slon` and `elon`), and the month of occurrence (`mo`).

```{r}
# Subset the data
tornado_map_data <- tornado[, c("slat", "slon", "elat", "elon", "mo","st")]
```

II. Create Seasonal and Regional Aggregations:

Count tornado occurrences by month and region (state).

```{r}
# Count tornado occurrences by month

tornado$mo <- factor(tornado$mo, levels = 1:12, labels = month.abb)


tornado_monthly_counts  <- tornado_map_data %>%
  group_by(mo) %>%
  summarise(total_tornadoes = n())

print(tornado_monthly_counts )

```

Count tornado occurrences by region (state).

```{r}

# Calculate the total number of tornadoes by state
tornado_state_counts  <- tornado_map_data  %>%
  group_by(st) %>%
  summarise(total_tornadoes = n())%>%
   arrange(desc( total_tornadoes))

print(tornado_state_counts)

```

III. Create Interactive Maps and plots:

Create interactive plot for monthly tornado variation.

```{r}

library(plotly)

plot_ly(data = tornado_monthly_counts , x = ~mo, y = ~total_tornadoes, type = "scatter", mode = "lines+markers", 
        name = "Tornado Count", line = list(color = "blue")) %>%
  layout(title = "Tornado Occurrences by Month",
         xaxis = list(title = "Month", tickmode = "array", tickvals = 1:12, ticktext =month.name),
         yaxis = list(title = "Tornado Count"))

```

Create interactive map using `leaflet` to visualize state-wise tornado count

```{r}
library(leaflet)
library(dplyr)
library(sf)
library(usmap)
library(maps)  

# Create a summary data frame with tornado counts by state
tornado_counts <- tornado %>%
  group_by(state_full) %>%
  summarise(tornado_count = n())

# Load a data frame mapping state names to state abbreviations
state_abbreviations <- data.frame(
  state_full = state.name,
  state_abbr = state.abb
)

# Merge tornado counts with state abbreviations
tornado_counts <- merge(tornado_counts, state_abbreviations, by = "state_full")

# Load U.S. state map data
us_states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))

# Check and fix invalid geometries
us_states1 <- st_make_valid(us_states)
# Convert 'ID' column in 'us_states1' to lowercase
us_states1$ID <- tolower(us_states1$ID)

# Convert 'state_full' column in 'tornado_counts' to lowercase
tornado_counts$state_full <- tolower(tornado_counts$state_full)

# Merge tornado counts with U.S. state map (case-insensitive)
us_states <- merge(us_states1, tornado_counts, by.x = "ID", by.y = "state_full", all.x = TRUE)


# Create an interactive map
# Create an interactive map with a different fill color
leaflet(data = us_states) %>%
  addProviderTiles("CartoDB.Voyager") %>%
  addPolygons(
    fillColor = ~colorQuantile("YlOrRd", us_states$tornado_count)(us_states$tornado_count),
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(color = "white", weight = 2, bringToFront = TRUE),
    label = ~paste(us_states$ID,
                   "Tornado Count:", tornado_count)
  ) %>%
  addLegend(
    position = "bottomright",
    pal = colorQuantile("YlOrRd", us_states$tornado_count),
    values = us_states$tornado_count,
    title = "Tornado Count",
    opacity = 0.7
  ) %>%
  addMiniMap(toggleDisplay = TRUE)


```

IV. Interpret the Results:

In this analysis, we explore the seasonal and regional patterns of tornado occurrences in the data set spanning from 1950 to 2022. The objective is to identify if there are specific months or states that exhibit higher tornado activity. To understand the seasonal variations, we aggregate tornado occurrences by month and observe the distribution.

**Seasonal Patterns:**

The monthly aggregation of tornado occurrences reveals the following insights:

March (mo = 3): March exhibits a substantial increase in tornado occurrences with 4,748 tornadoes. This could be attributed to the transition from winter to spring, creating favorable conditions for tornado formation.

April and May (mo = 4, 5): April and May experience the highest tornado activity, with 9,792 and 15,057 tornadoes, respectively. These months typically mark the peak of tornado season, characterized by the convergence of warm and cold air masses.

June (mo = 6): Tornado activity remains elevated in June with 12,615 tornadoes, indicating a continuation of favorable weather conditions for tornado formation.

July to December (mo = 7-12): Tornado occurrences gradually decrease from July onwards, reaching the lowest point in December. This decline is consistent with the typical seasonal patterns, where tornadoes are less frequent in the colder months.

**Regional Patterns:**

The regional analysis, based on the total number of tornadoes by state, provides insights into the distribution of tornado activity across different states:

Texas (TX): Texas (TX) leads in tornado occurrences with 9,267 tornadoes, reinforcing its reputation as a tornado-prone state.

Kansas (KS) and Oklahoma (OK): Kansas and Oklahoma follow closely with 4,429 and 4,146 tornadoes, respectively. The central United States, often part of "Tornado Alley," demonstrates a high tornado frequency.

Florida (FL): Florida (FL) experiences significant tornado activity, recording 3,566 tornadoes. This suggests that tornadoes are not exclusive to the central plains but can also impact southeastern states.

Nebraska (NE) and Iowa (IA): Nebraska and Iowa have notable tornado occurrences, emphasizing the broader geographic distribution of tornado-prone regions.

**Combined Analysis**

The combined analysis of seasonal and regional patterns underscores the importance of understanding both temporal and spatial aspects of tornado occurrences. Tornadoes exhibit distinct seasonality, peaking in spring, while certain states consistently experience higher tornado activity throughout the year. This knowledge is crucial for implementing effective preparedness and mitigation strategies tailored to specific regions and times of heightened risk.

### Tornado Impact Assessment

**1. Assess the human impact of tornadoes by analyzing variables such as injuries, fatalities.**

Certainly! To investigate the correlation between the magnitude of tornadoes (using the F-scale) and the extent of injuries, fatalities, or losses, you can follow these steps:

I. Subset Data for Relevant Variables

```{r}
# Subset data for relevant variables
tornado_impact_subset <- tornado[, c("yr","state_full","st","mag", "inj", "fat", "loss", "closs","f1",
                                     "f2","f3","f4","stf")]

# Check for missing values
#summary(tornado_impact_subset)
```

II. Identify tornado Injuries and Fatalities by year:

Summarize the total number of injuries and fatalities for each year.

```{r}

# Aggregate injuries and fatalities by year
total_impact_by_year <- aggregate(cbind(inj, fat) ~ yr, data = tornado_impact_subset, sum)
total_impact_by_year

```


Generate a line plot to visualize the trends in fatalities and injuries over the years.

```{r}

plot(total_impact_by_year$yr, total_impact_by_year$inj, type = "l", col = "blue", xlab = "Year", ylab = "Count", main = "Tornado Injuries and Fatalities Over Years")

lines(total_impact_by_year$yr, total_impact_by_year$fat, type = "l", col = "red")

legend("topright", legend = c("Injuries", "Fatalities"), col = c("blue", "red"), lty = 1, bty = "n")
# Adjust the plot margins to make room for the legend
#par(mar = c(5, 5, 4, 5) + 0.1)


```


III. Identify tornado Injuries and Fatalities by EF rating:


Summarize the total number of injuries and fatalities by magnitude (mag) while excluding the value -9 to get EF rating.


```{r}

# Aggregate injuries and fatalities by magnitude (excluding mag == -9)
total_impact_by_mag <- tornado_impact_subset %>%
  filter(mag != -9) %>%
  group_by(mag) %>%
  summarise(total_injuries = sum(inj), total_fatalities = sum(fat))


```


Generate a bar plot to visualize the total injuries and fatalities for each EF rating.

```{r}
# Create a bar plot for injuries and fatalities by magnitude
ggplot(total_impact_by_mag, aes(x = factor(mag))) +
  geom_bar(aes(y = total_fatalities, fill = "Fatalities"), stat = "identity", position = "dodge", width = 0.7) +
  geom_bar(aes(y = total_injuries, fill = "Injuries"), stat = "identity", position = "dodge", width = 0.5) +
  labs(title = "Tornado Injuries and Fatalities by EF Rating",
       x = "EF Rating ",
       y = "Count") +
  scale_fill_manual(values = c("blue", "red"), name = "Impact Type") +
  theme_minimal() +
  #theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(fill = guide_legend(title = "Impact Type"))



```


IV. Identify tornado Injuries and Fatalities by State and visualizing:


Count no of tornado Injuries and Fatalities by State

```{r}
# Create a summary data frame with tornado Injuries and Fatalities by State 
total_impact_by_st <- tornado_impact_subset %>%
  group_by(state_full) %>%
  summarise(total_injuries = sum(inj), total_fatalities = sum(fat))
total_impact_by_st
```



Create interactive map using `leaflet` to visualize state-wise tornado Injuries and Fatalities

```{r}

library(leaflet)
library(dplyr)
library(sf)
library(usmap)
library(maps)  

# Create a summary data frame with tornado Injuries and Fatalities by State 
total_impact_by_st <- tornado_impact_subset %>%
  group_by(state_full) %>%
  summarise(total_injuries = sum(inj), total_fatalities = sum(fat))


state_abbreviations <- data.frame(
  state_full = state.name,
  state_abbr = state.abb
)


total_impact_by_st <- merge(total_impact_by_st, state_abbreviations, by = "state_full")

us_states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))
us_states1 <- st_make_valid(us_states)
us_states1$ID <- tolower(us_states1$ID)
total_impact_by_st$state_full <- tolower(total_impact_by_st$state_full)

us_states <- merge(us_states1, total_impact_by_st, by.x = "ID", by.y = "state_full", all.x = TRUE)

leaflet(data = us_states) %>%
  addProviderTiles("CartoDB.Voyager") %>%
  addPolygons(
    highlightOptions = highlightOptions(color = "white", weight = 2, bringToFront = TRUE),
    label = ~paste(us_states$ID,
                   "Tornado Injuries:", us_states$total_injuries,
                   "Tornado Fatalities:", us_states$total_fatalities)
  ) 
  

```





**2. Assess the economic  impact of tornadoes by analyzing variables such as property and crop losses.**


**3. Explore the spatial distribution of tornado impact, focusing on the geographical areas most affected by these natural disasters.**

## Developing Shiny Application

**1. The Shiny application will be built to import and utilize the tornado data set.**

### Data Analyzing Approach

1.  Identifying and addressing missing values in the tornado data set. This will involve techniques such as imputation or removal of rows with significant missing data. Special attention will be given to critical columns, such as **inj**, **fat**, and **mag**. And perform outlier detection to identify data points that significantly deviate from the norm

2.  Data inconsistencies, such as conflicting records or contradictory information, will be resolved. This may involve cross-referencing with external sources particularly in FIPS Codes for Counties (**f1**, **f2**, **f3**, **f4**).

3.  Additional features or variables may be created to enhance the analysis. For example, calculate the total impact (injuries, fatalities, loss) for each tornado event, create time-based variables (season, time of day).

4.  To examine long-term trends in tornado frequency and intensity, we can perform a time series analysis of tornado occurrences over the years, studying variations in the number and intensity of tornadoes.

5.  For investigating seasonal and regional variations in tornado occurrences, we can create visualizations and summaries that highlight the months and states with the highest tornado activity, using the **mo**, **st**, and **stf** columns.

6.  To investigate the distribution of tornado magnitudes, we can create histograms and box plots of the **mag** column, which represents tornado intensity. We can also examine changes in tornado magnitude over time.

7.  To assess the economic and human impact of tornadoes, we can calculate statistics such as the mean, median, and maximum values of injuries, fatalities, property losses, and crop losses. This will help identify trends and the most severely affected areas.

8.  Analyzing the geographical distribution of tornado impact can be done by mapping the areas with the highest impacts and visualizing the affected regions.

9.  With the data analysis approach mentioned earlier, we are planing to add those in to a Shiny web application with implementing a variety of interactive visualizations within the Shiny application to address each of the project's goals more effectively. For instance:

-   Time series plots for trend analysis.
-   Heatmaps, choropleth maps, or scatter plots to visualize regional and seasonal variations.
-   Box plots, histograms, and distribution curves for magnitude and impact analysis.
-   Interactive maps for visualizing tornado impact locations.

Describe any data cleaning and rearranging you needed to do to get your dataset into a workable form. Make sure to cite any packages which were important in your data cleaning process in this section. For instance, if you used dplyr, then it would be appropriate to say something like

> we used the group-apply-combine paradigm with the `dplyr` functions `group_by` and `summarize` [@dplyr-package] to generate a dataset for each day of the observation period from the 15-minute interval observations in the raw data set.

## Topic of Exploration

Here, you want to introduce the first topic you want to explore with your (newly cleaned up) data. Code to process data should be contained in chunks above this point, and those chunks should *not* be included in the report.

You can add options to executable code like this

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).

If you generate a figure, it should have a caption. Here's a demonstration of how to do that:

```{r iris-plot}
#| label: fig-iris
#| fig-width: 8
#| fig-height: 4 # Change the figure dimensions using fig-width/height
#| out-width: 80% # This changes the size of the figure as rendered in the text. 
#| fig-cap: "This figure shows the relationship between sepal width and petal width in irises. I've used geom_jitter to combat overplotting, as the data are measured in relatively consistent increments. The figure is drawn with `ggplot2` [@ggplot2-package]."
#| echo: false


data(iris)
library(ggplot2)
ggplot(iris, aes(x = Sepal.Width, y = Petal.Width, color = Species)) + 
  geom_jitter() + 
  xlab("Sepal Width (cm)") + ylab("Petal Width (cm)") + 
  ggtitle("Sepal and Petal Dimensions")
```

Then, you can reference @fig-iris in the text and the appropriate cross-reference will be generated.

You can find additional information about formatting figures generated from code in the [quarto documentation](https://quarto.org/docs/authoring/figures.html#computations).

## Additional Exploration topic

Add another topic here... as many as you desire, really. Make sure to include a transition between the two sections that connects the two with some sort of logical train of thought.

## Conclusion

Here, you want to summarize the main points of what you've learned from this investigation, in paragraph form.

## Tips

(delete this section from your report!)

Almost anything you might want to know about how to format output in quarto can be found [here](https://quarto.org/docs/authoring/markdown-basics.html). Feel free to email/come to office hours to figure out how to do XYZ - part of the goal of making you write this report is that I want you to know how to write e.g. a journal paper in Quarto as well, so now's the time to experiment.

If you want to know what the wordcount of your report is, you can run the following command in your terminal:

```         
pandoc --lua-filter wordcount.lua report.qmd
```

Notice that I have not pushed `_output/report.html` or the `_output/report_files/` folder to github - this is intentional. I have actually set `_output` to not show up in git, to encourage you all to NOT push the rendered files to github and to instead work from the markdown files directly.

You may find it cleaner to create a figure subdirectory and store any figures that aren't created by R/Python in that folder. I encourage you to organize this repository in a sensible way.
